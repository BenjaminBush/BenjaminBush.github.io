<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://benjaminbush.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://benjaminbush.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-13T22:14:09+00:00</updated><id>https://benjaminbush.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Nano Med GPT Part 1</title><link href="https://benjaminbush.github.io/blog/2023/nano_medgpt_1/" rel="alternate" type="text/html" title="Nano Med GPT Part 1"/><published>2023-11-09T15:09:00+00:00</published><updated>2023-11-09T15:09:00+00:00</updated><id>https://benjaminbush.github.io/blog/2023/nano_medgpt_1</id><content type="html" xml:base="https://benjaminbush.github.io/blog/2023/nano_medgpt_1/"><![CDATA[<h1 id="nano-med-gpt-series">Nano Med GPT Series</h1> <p><a href="https://github.com/BenjaminBush/nano_medgpt/tree/main">Nano Med GPT</a> is a small-scale version of the GPT-2 language model trained on medical note data. Although there are more advanced tools available, such as <a href="https://www.nuance.com/healthcare/ambient-clinical-intelligence/explore-dax-for-clinicians.html">DAX Dragon Express</a> (which help provide inspiration for this project), this important use case presents a strong opportunity for hands-on learning and development with transformer-based DNN architectures. This blog series will be broken into the following parts:</p> <ul> <li>Part 1 - Problem Statement, Dataset, and Local Machine Development</li> <li>Part 2 - Scaling Up DNN on Azure, Effectiveness</li> </ul> <h1 id="problem-statement">Problem Statement</h1> <p>Clinicians spend nearly 2 hours per day outside of regular working hours writing notes in a patientâ€™s chart. This time consuming task can lead to clinician burnout. Generative AI can assist with documentation by suggesting autocompletion, which may reduce the time required to complete a note and therefore alleviate some burden on the clinician.</p> <h1 id="dataset">Dataset</h1> <p>For this project, we make use of the <a href="https://physionet.org/content/mimiciv/2.2/">MIMIC-IV Dataset</a>. MIMIC-IV is the latest version of a database comprising the deidentified health-related data from patients who were admitted to the critical care units of the Beth Israel Deaconess Medical Center between 2008-2019. I am grateful to the producers and owners of the database for providing access. Those that are interested in gaining access to the dataset can follow the instructions detailed <a href="https://mimic.mit.edu/docs/gettingstarted/">here</a>.</p> <p>MIMIC-IV provides a wealth of interesting data for myriad research purposes. For this project, we are interested in the <code class="language-plaintext highlighter-rouge">mimiciv_note</code> module, which includes deidentified free text clinical notes for hospital details. We are specifically intersted in the discharge summaries, which can be found in the <code class="language-plaintext highlighter-rouge">discharge</code> table.</p> <h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2> <p>number of notes distribution of note length total raw vocabulary size (words, characters) what data is de-identified what is the general format of the note?</p> <h1 id="initial-development">Initial Development</h1> <p>Thanks for joining! Please stay tuned for Part 2 of the blog series where we will cover how to scale our model size and dataset size up using the cloud, as well as evaluate the effectiveness of our model.</p>]]></content><author><name></name></author><category term="llm"/><category term="gpt"/><category term="medical_notes"/><summary type="html"><![CDATA[Part 1 of the Nano Med GPT series]]></summary></entry></feed>